{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "aiffel",
      "language": "python",
      "name": "aiffel"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "E11.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zeze79/kakao-clone/blob/master/explore_11/E11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6ZwIgj3xWyM"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "import re                  # 정규표현식을 위한 Regex 지원 모듈 (문장 데이터를 정돈하기 위해) \n",
        "import numpy as np         # 변환된 문장 데이터(행렬)을 편하게 처리하기 위해\n",
        "import tensorflow as tf    # 대망의 텐서플로우!\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J292gC1SxWyM",
        "outputId": "1a5772ec-bb62-4ca6-e7ff-515fa1826fbd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3s1fK9ywxWyN"
      },
      "source": [
        "## Step 1. 데이터 읽어오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ezfd2mvxWyN",
        "outputId": "17551ea2-0450-4bda-d27a-88dfc8ad8f9c"
      },
      "source": [
        "\n",
        "txt_file_path = '/content/drive/MyDrive/Colab Notebooks/explore/lyricist/data/lyrics/*'\n",
        "\n",
        "txt_list = glob.glob(txt_file_path)\n",
        "\n",
        "raw_corpus = []\n",
        "\n",
        "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
        "for txt_file in txt_list:\n",
        "    with open(txt_file, \"r\") as f:\n",
        "        raw = f.read().splitlines()\n",
        "        raw_corpus.extend(raw)\n",
        "\n",
        "print(\"데이터 크기:\", len(raw_corpus))\n",
        "print(\"Examples:\\n\", raw_corpus[:3])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "데이터 크기: 187088\n",
            "Examples:\n",
            " ['They say get ready for the revolution', \"I think it's time we find some sorta solution\", \"Somebody's caught up in the endless pollution\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HOOIoxxxWyN"
      },
      "source": [
        "## Step 2. 데이터 정제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8-w4LFgxWyN",
        "outputId": "42b82a7f-9d8c-4367-cf4f-71af1e49b9c7"
      },
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip()       # 소문자로 바꾸고 양쪽 공백을 삭제\n",
        "  \n",
        "    # 아래 3단계를 거쳐 sentence는 스페이스 1개를 delimeter로 하는 소문자 단어 시퀀스로 바뀝니다.\n",
        "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)        # 패턴의 특수문자를 만나면 특수문자 양쪽에 공백을 추가\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)                  # 공백 패턴을 만나면 스페이스 1개로 치환\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)  # a-zA-Z?.!,¿ 패턴을 제외한 모든 문자(공백문자까지도)를 스페이스 1개로 치환\n",
        "\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    sentence = '<start> ' + sentence + ' <end>'      # 이전 스텝에서 본 것처럼 문장 앞뒤로 <start>와 <end>를 단어처럼 붙여 줍니다\n",
        "    \n",
        "    return sentence\n",
        "\n",
        "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))   # 이 문장이 어떻게 필터링되는지 확인해 보세요.\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> this is sample sentence . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw9qRbG5xWyN",
        "outputId": "22c81e08-2151-4e99-854f-1db637809eeb"
      },
      "source": [
        "corpus = []\n",
        "\n",
        "for sentence in raw_corpus:\n",
        "    if len(sentence) == 0: continue\n",
        "    if sentence[-1] == \":\": continue\n",
        "        \n",
        "    corpus.append(preprocess_sentence(sentence))\n",
        "        \n",
        "corpus[:10]\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> they say get ready for the revolution <end>',\n",
              " '<start> i think it s time we find some sorta solution <end>',\n",
              " '<start> somebody s caught up in the endless pollution <end>',\n",
              " '<start> they need to wake up , stop living illusions i know you need to hear this <end>',\n",
              " '<start> why won t somebody feel this <end>',\n",
              " '<start> this is my wish that we all feel connected <end>',\n",
              " '<start> this is my wish that nobodies neglected be like a rocket baby <end>',\n",
              " '<start> be like a rocket take off <end>',\n",
              " '<start> just fly , away ay , ay <end>',\n",
              " '<start> to find your space take off <end>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oo_Wc48kxWyN",
        "outputId": "c0443a8a-e8de-4cbd-e1d6-9720304ea045"
      },
      "source": [
        "#tf keras txt tokenizer\n",
        "def tokenize(corpus):\n",
        "    # 텐서플로우에서 제공하는 Tokenizer 패키지를 생성\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "        num_words=12000,  # 전체 단어의 개수 \n",
        "        filters=' ',    # 별도로 전처리 로직을 추가할 수 있습니다. 이번에는 사용하지 않겠습니다.\n",
        "        oov_token=\"<unk>\"  # out-of-vocabulary, 사전에 없었던 단어는 어떤 토큰으로 대체할지\n",
        "    )\n",
        "    tokenizer.fit_on_texts(corpus)   # 우리가 구축한 corpus로부터 Tokenizer가 사전을 자동구축하게 됩니다.\n",
        "\n",
        "    # 이후 tokenizer를 활용하여 모델에 입력할 데이터셋을 구축하게 됩니다.\n",
        "    tensor = tokenizer.texts_to_sequences(corpus)   # tokenizer는 구축한 사전으로부터 corpus를 해석해 Tensor로 변환합니다.\n",
        "\n",
        "    # 입력 데이터의 시퀀스 길이를 일정하게 맞추기 위한 padding  메소드를 제공합니다.\n",
        "    # maxlen의 디폴트값은 None입니다. 이 경우 corpus의 가장 긴 문장을 기준으로 시퀀스 길이가 맞춰집니다.\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen=15) \n",
        "\n",
        "    print(tensor,tokenizer)\n",
        "    return tensor, tokenizer\n",
        "\n",
        "tensor, tokenizer = tokenize(corpus)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  2  45  68 ...   0   0   0]\n",
            " [  2   5 126 ...   0   0   0]\n",
            " [  2 265  16 ...   0   0   0]\n",
            " ...\n",
            " [  2  31  21 ...   1   3   0]\n",
            " [  2 338  21 ...   3   0   0]\n",
            " [  2  42 130 ...   0   0   0]] <keras_preprocessing.text.Tokenizer object at 0x7fc18cecf748>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy1r3GrExWyN",
        "outputId": "57e0b1bc-5206-4a62-f035-2f3683dded0b"
      },
      "source": [
        "print(tensor[:3, :10])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   2   45   68   43  297   28    6 2109    3    0]\n",
            " [   2    5  126   11   16   73   23  204   99 3845]\n",
            " [   2  265   16  635   29   14    6 2963    1    3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQ3qf5a4xWyN",
        "outputId": "37bc0a0a-6e1b-433e-b179-99a2b557a980"
      },
      "source": [
        "for idx in tokenizer.index_word:\n",
        "    print(idx, \":\", tokenizer.index_word[idx])\n",
        "\n",
        "    if idx >= 10: break"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 : <unk>\n",
            "2 : <start>\n",
            "3 : <end>\n",
            "4 : ,\n",
            "5 : i\n",
            "6 : the\n",
            "7 : you\n",
            "8 : and\n",
            "9 : a\n",
            "10 : to\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VD-h84EuxWyO",
        "outputId": "d6029ee4-4276-440e-d482-9d1885ec1757"
      },
      "source": [
        "src_input = tensor[:, :-1]  # tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성합니다. 마지막 토큰은 <END>가 아니라 <pad>일 가능성이 높습니다.\n",
        "tgt_input = tensor[:, 1:]    # tensor에서 <START>를 잘라내서 타겟 문장을 생성합니다.\n",
        "\n",
        "print(src_input[0])\n",
        "print(tgt_input[0])\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   2   45   68   43  297   28    6 2109    3    0    0    0    0    0]\n",
            "[  45   68   43  297   28    6 2109    3    0    0    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvIIX2uMxWyO",
        "outputId": "209168cf-4432-426a-ddbc-1b7e7e858322"
      },
      "source": [
        "BUFFER_SIZE = len(src_input)\n",
        "BATCH_SIZE = 256\n",
        "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
        "\n",
        "VOCAB_SIZE = tokenizer.num_words + 1    # tokenizer가 구축한 단어사전 내 7000개와, 여기 포함되지 않은 0:<pad>를 포함하여 7001개\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "dataset"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "rTPvYluOxWyO",
        "outputId": "121594a3-9772-4d74-f708-4854a78d392c"
      },
      "source": [
        "#tensors = np.array(tensors)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-6e8274d4b4c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tensors' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg62QEpkxWyO"
      },
      "source": [
        "## Step 3. 평가데이터셋 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK-Nrm-GxWyO"
      },
      "source": [
        "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input, test_size=0.2)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQX4hxV6xWyO",
        "outputId": "49f9dabb-57d8-4c7a-d69b-b6bf3ab5daf4"
      },
      "source": [
        "print(\"Source Train:\", enc_train.shape)\n",
        "print(\"Target Train:\", dec_train.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Source Train: (140599, 14)\n",
            "Target Train: (140599, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cSFh53UxWyO"
      },
      "source": [
        "## Step 4. 인공지능 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QdQWuxVxWyO",
        "outputId": "5282449a-0f9d-49b2-a9c5-1179650ba234"
      },
      "source": [
        "tokenizer.num_words"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMJqWjz3xWyO"
      },
      "source": [
        "### model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ8HxY05xWyO"
      },
      "source": [
        "class TextGenerator(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
        "        super(TextGenerator, self).__init__()\n",
        "        \n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.rnn_1(out)\n",
        "        out = self.rnn_2(out)\n",
        "        out = self.linear(out)\n",
        "        \n",
        "        return out\n",
        "    \n",
        "embedding_size = 256\n",
        "hidden_size = 1024\n",
        "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvpMBdTzxWyO",
        "outputId": "c69d977f-b99b-4fda-bf2b-18a28ee8ef48"
      },
      "source": [
        "for src_sample, tgt_sample in dataset.take(1):\n",
        "    break\n",
        "model(src_sample)\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
              "array([[[ 4.60201773e-05, -9.66208681e-05, -1.09552733e-04, ...,\n",
              "          1.61692049e-04, -4.44294710e-05,  2.16669534e-04],\n",
              "        [ 2.38142980e-04,  1.05256513e-04, -9.17766156e-05, ...,\n",
              "          6.80893718e-04, -2.10979066e-04,  2.94500613e-04],\n",
              "        [ 3.47258610e-04,  2.27052325e-04,  3.51493873e-05, ...,\n",
              "          1.03231263e-03, -2.80695589e-04,  2.55632855e-04],\n",
              "        ...,\n",
              "        [-1.30599481e-03, -8.11637379e-04, -7.23538033e-05, ...,\n",
              "          1.94792898e-04,  9.02261294e-04, -3.77925142e-04],\n",
              "        [-1.51122292e-03, -8.62084678e-04, -3.57041630e-04, ...,\n",
              "         -3.32167721e-04,  7.34721543e-04, -2.11167484e-04],\n",
              "        [-1.70101190e-03, -8.77295097e-04, -6.17565995e-04, ...,\n",
              "         -8.17824563e-04,  5.03106334e-04, -5.11878352e-05]],\n",
              "\n",
              "       [[ 4.60201773e-05, -9.66208681e-05, -1.09552733e-04, ...,\n",
              "          1.61692049e-04, -4.44294710e-05,  2.16669534e-04],\n",
              "        [-1.67492362e-05, -9.46159562e-05, -1.06174310e-04, ...,\n",
              "          3.35775694e-04,  9.70869005e-05,  1.68894432e-04],\n",
              "        [-3.87354346e-04, -1.00599682e-04, -2.02508279e-04, ...,\n",
              "          4.58244525e-04,  1.03250321e-04,  3.39653634e-04],\n",
              "        ...,\n",
              "        [-1.68751215e-03, -5.64061338e-04, -1.03757682e-03, ...,\n",
              "          5.81656568e-05,  9.34061609e-05,  1.47476140e-03],\n",
              "        [-1.79843884e-03, -5.78059058e-04, -1.24900113e-03, ...,\n",
              "         -3.98520788e-04, -6.98951699e-05,  1.42113864e-03],\n",
              "        [-1.90969033e-03, -5.65833645e-04, -1.41592906e-03, ...,\n",
              "         -8.15334090e-04, -2.76269566e-04,  1.36263354e-03]],\n",
              "\n",
              "       [[ 4.60201773e-05, -9.66208681e-05, -1.09552733e-04, ...,\n",
              "          1.61692049e-04, -4.44294710e-05,  2.16669534e-04],\n",
              "        [ 3.39821145e-06, -3.36761324e-04, -3.59952683e-04, ...,\n",
              "          3.34603421e-04, -2.53546401e-04,  2.28121891e-04],\n",
              "        [-2.54313982e-05, -5.08446654e-04, -4.70426632e-04, ...,\n",
              "          5.62838628e-04, -1.96854104e-04,  2.46982490e-05],\n",
              "        ...,\n",
              "        [-1.97194703e-03, -1.35095645e-04, -1.40335620e-03, ...,\n",
              "         -1.38826738e-03, -2.36588294e-05, -4.70573781e-04],\n",
              "        [-2.09931261e-03, -1.69262770e-04, -1.54229894e-03, ...,\n",
              "         -1.71953347e-03, -2.28676407e-04, -2.94424564e-04],\n",
              "        [-2.20602518e-03, -1.89446480e-04, -1.64540322e-03, ...,\n",
              "         -1.98431709e-03, -4.52496315e-04, -1.21356366e-04]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 4.60201773e-05, -9.66208681e-05, -1.09552733e-04, ...,\n",
              "          1.61692049e-04, -4.44294710e-05,  2.16669534e-04],\n",
              "        [ 4.39980467e-05, -3.97889409e-04, -4.29909560e-04, ...,\n",
              "          1.68199869e-04,  9.24718406e-05,  2.33406303e-04],\n",
              "        [-5.86105634e-05, -7.36950838e-04, -8.39717395e-04, ...,\n",
              "          3.96624411e-04,  1.96827343e-04,  1.94596461e-04],\n",
              "        ...,\n",
              "        [ 2.69787473e-04, -1.04284927e-03, -8.91036645e-04, ...,\n",
              "          1.63723226e-03,  3.98138305e-04,  9.22958774e-04],\n",
              "        [ 1.11130925e-04, -1.12462125e-03, -9.85701568e-04, ...,\n",
              "          1.33828609e-03,  5.33643994e-04,  9.99868615e-04],\n",
              "        [-1.09895722e-04, -1.19367021e-03, -1.11084862e-03, ...,\n",
              "          8.82323540e-04,  5.79371292e-04,  1.04251795e-03]],\n",
              "\n",
              "       [[ 4.60201773e-05, -9.66208681e-05, -1.09552733e-04, ...,\n",
              "          1.61692049e-04, -4.44294710e-05,  2.16669534e-04],\n",
              "        [ 1.04825383e-04, -1.04259874e-04, -8.25816751e-05, ...,\n",
              "          2.46590120e-04, -1.40547985e-04,  1.81910786e-04],\n",
              "        [-5.00784336e-05, -1.05661078e-04,  1.87923099e-04, ...,\n",
              "          1.50318301e-04, -1.21957884e-04,  1.87101396e-04],\n",
              "        ...,\n",
              "        [-7.78189569e-04, -8.74367892e-04, -6.31169765e-04, ...,\n",
              "         -1.65487081e-03,  3.23245185e-04, -4.53886983e-04],\n",
              "        [-9.96161485e-04, -8.04309384e-04, -8.57192616e-04, ...,\n",
              "         -1.99028663e-03,  1.83856595e-04, -2.21365190e-04],\n",
              "        [-1.20777509e-03, -7.21974764e-04, -1.05134421e-03, ...,\n",
              "         -2.26247474e-03, -3.61459030e-07, -8.33516606e-06]],\n",
              "\n",
              "       [[ 4.60201773e-05, -9.66208681e-05, -1.09552733e-04, ...,\n",
              "          1.61692049e-04, -4.44294710e-05,  2.16669534e-04],\n",
              "        [ 1.57311602e-04, -3.17474158e-04, -8.03922812e-05, ...,\n",
              "          3.95178678e-04,  3.00012762e-05,  2.61726294e-04],\n",
              "        [ 2.52487720e-04, -2.26684337e-04,  8.01661372e-06, ...,\n",
              "          2.59412802e-04,  1.88917738e-06,  3.78271652e-04],\n",
              "        ...,\n",
              "        [-1.67300017e-03, -2.68077536e-04, -1.64191774e-03, ...,\n",
              "         -1.88004773e-03, -5.68912597e-04,  7.46216218e-04],\n",
              "        [-1.83104165e-03, -2.22559407e-04, -1.69404864e-03, ...,\n",
              "         -2.03235960e-03, -8.03961535e-04,  8.09096848e-04],\n",
              "        [-1.96220260e-03, -1.75645633e-04, -1.72525621e-03, ...,\n",
              "         -2.14964664e-03, -1.03353057e-03,  8.69624433e-04]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKafL_PExWyO",
        "outputId": "fd4f6610-c441-47da-f2c8-95f01e59ed56"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"text_generator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        multiple                  3072256   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  multiple                  5246976   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                multiple                  8392704   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  12301025  \n",
            "=================================================================\n",
            "Total params: 29,012,961\n",
            "Trainable params: 29,012,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeUFX3eHxWyO"
      },
      "source": [
        "### loss & optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0qqeLvKxWyO"
      },
      "source": [
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9fPQIhYxWyO"
      },
      "source": [
        "### trainning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3hxED-6xWyO",
        "outputId": "f38b7510-b516-47d3-e0af-641f387b4c6f"
      },
      "source": [
        "model.compile(loss=loss, optimizer=optimizer)\n",
        "model.fit(x=enc_train, y=dec_train, validation_data=(enc_val, dec_val), batch_size=BATCH_SIZE, epochs=10)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "550/550 [==============================] - 107s 195ms/step - loss: 3.7023 - val_loss: 3.3355\n",
            "Epoch 2/10\n",
            "550/550 [==============================] - 113s 206ms/step - loss: 3.2046 - val_loss: 3.1336\n",
            "Epoch 3/10\n",
            "550/550 [==============================] - 117s 212ms/step - loss: 3.0155 - val_loss: 3.0028\n",
            "Epoch 4/10\n",
            "550/550 [==============================] - 118s 214ms/step - loss: 2.8707 - val_loss: 2.9114\n",
            "Epoch 5/10\n",
            "550/550 [==============================] - 117s 212ms/step - loss: 2.7485 - val_loss: 2.8415\n",
            "Epoch 6/10\n",
            "550/550 [==============================] - 117s 213ms/step - loss: 2.6380 - val_loss: 2.7875\n",
            "Epoch 7/10\n",
            "550/550 [==============================] - 117s 213ms/step - loss: 2.5345 - val_loss: 2.7353\n",
            "Epoch 8/10\n",
            "550/550 [==============================] - 118s 214ms/step - loss: 2.4368 - val_loss: 2.6962\n",
            "Epoch 9/10\n",
            "550/550 [==============================] - 117s 213ms/step - loss: 2.3447 - val_loss: 2.6613\n",
            "Epoch 10/10\n",
            "550/550 [==============================] - 117s 213ms/step - loss: 2.2575 - val_loss: 2.6349\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc18caff710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlYt8Yme43Pq"
      },
      "source": [
        "## Step5. 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Tl8EvKzUxWyO",
        "outputId": "40d94d54-fbb9-4a19-db70-0053a2aeb577"
      },
      "source": [
        "def generate_text(model, tokenizer, init_sentence='<start> i love', max_len=20):\n",
        "    \n",
        "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
        "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
        "    end_token = tokenizer.word_index['<end>']\n",
        "    \n",
        "    while True:\n",
        "        predict = model(test_tensor)\n",
        "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:,-1]\n",
        "        \n",
        "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
        "        \n",
        "        if predict_word.numpy()[0] == end_token:break\n",
        "        if test_tensor.shape[1] >= max_len:break\n",
        "    \n",
        "    generated = \"\"\n",
        "    \n",
        "    for word_index in test_tensor[0].numpy():\n",
        "        generated += tokenizer.index_word[word_index] + \" \"\n",
        "    \n",
        "    return generated\n",
        "\n",
        "generate_text(model, tokenizer, init_sentence='<start> i love', max_len=20)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<start> i love you , i m gonna be <end> '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "n4dyf2265FfO",
        "outputId": "901d3837-9c90-4bb2-d627-56f8976273c8"
      },
      "source": [
        "generate_text(model, tokenizer, init_sentence='<start> i hate', max_len=20)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<start> i hate the way you lie <end> '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vxV3M9o65GAw",
        "outputId": "2117f10b-a53e-4526-f087-f79e09e118be"
      },
      "source": [
        "generate_text(model, tokenizer, init_sentence='<start> if you', max_len=20)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<start> if you want me , i m not gonna crack my mind <end> '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qNxarmIz5J7G",
        "outputId": "75707985-aaa3-4b9b-9b7f-a523253593f1"
      },
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> show me the \", max_len=20)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<start> show me the place <end> '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FKvsgWIc5OS3",
        "outputId": "1d772319-e554-47c2-aef3-d2b5426bc3d9"
      },
      "source": [
        "generate_text(model, tokenizer, init_sentence=\"<start> i am\", max_len=20)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<start> i am not throwing away my shot <end> '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEZqpcRO6Jr7"
      },
      "source": [
        ""
      ]
    }
  ]
}